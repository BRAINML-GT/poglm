{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3292d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import binned_statistic\n",
    "\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from poglm import model, utils, inference\n",
    "\n",
    "from importlib import reload\n",
    "reload(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac6c35c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-29T02:53:55.000391Z",
     "start_time": "2024-01-29T02:53:45.111240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(1676.4966)\n",
      "1 tensor(1615.7518)\n",
      "2 tensor(1605.7494)\n",
      "3 tensor(1601.5629)\n",
      "4 tensor(1599.0858)\n",
      "5 tensor(1597.3909)\n",
      "6 tensor(1596.1389)\n",
      "7 tensor(1595.1835)\n",
      "8 tensor(1594.4419)\n",
      "9 tensor(1593.8615)\n",
      "10 tensor(1593.4045)\n",
      "11 tensor(1593.0446)\n",
      "12 tensor(1592.7590)\n",
      "13 tensor(1592.5330)\n",
      "14 tensor(1592.3529)\n",
      "15 tensor(1592.2090)\n",
      "16 tensor(1592.0934)\n",
      "17 tensor(1592.0004)\n",
      "18 tensor(1591.9250)\n",
      "19 tensor(1591.8629)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    temp = loadmat(f'rgcData_Nature08/SpTimesRGC.mat', squeeze_me=False, struct_as_record=False)['SpTimes'][0]\n",
    "    n_time_bins = 20 * 60 * 120 # 20 min * 119.9820 Hz\n",
    "    time_bins = np.linspace(1, n_time_bins, n_time_bins)\n",
    "    n_neurons = 27\n",
    "    spikes = np.zeros((n_time_bins, n_neurons))\n",
    "    for i in range(n_neurons):\n",
    "        spikes[:, i] = binned_statistic(temp[i][:, 0], None, bins=np.hstack(([0], time_bins)), statistic='count')[0].T\n",
    "    return spikes\n",
    "\n",
    "spikes = load_data()\n",
    "\n",
    "## hyper-parameters\n",
    "decay = 0.25\n",
    "window_size = 5\n",
    "n_vis_neurons = spikes.shape[1]\n",
    "n_neurons = n_vis_neurons\n",
    "basis = utils.exp_basis(decay, window_size, window_size)\n",
    "\n",
    "\n",
    "vis_spikes_list_train, vis_spikes_list_test = torch.from_numpy(spikes[:96000].reshape(960, 100, -1)).to(torch.float32), torch.from_numpy(spikes[96000:].reshape(480, 100, -1)).to(torch.float32)\n",
    "convolved_vis_spikes_list_train = utils.convolve_spikes_with_basis(vis_spikes_list_train, basis, direction='forward')\n",
    "convolved_vis_spikes_list_test = utils.convolve_spikes_with_basis(vis_spikes_list_test, basis, direction='forward')\n",
    "train_dataset = TensorDataset(vis_spikes_list_train, convolved_vis_spikes_list_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "inf_model = model.POGLM(n_neurons, n_vis_neurons, basis)\n",
    "with torch.no_grad():\n",
    "    inf_model.linear.weight.data = torch.zeros((n_neurons, n_neurons))\n",
    "    inf_model.linear.bias.data = torch.zeros((n_neurons, ))\n",
    "    \n",
    "inf_optimizer = torch.optim.Adam(inf_model.parameters(), lr=0.02)\n",
    "\n",
    "n_epochs = 20\n",
    "print_freq = 1\n",
    "\n",
    "epoch_loss_list = torch.zeros(n_epochs)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for spikes_list, convolved_spikes_list in train_dataloader:\n",
    "        batch_size = spikes_list.shape[0]\n",
    "        loss = 0\n",
    "        for sample in range(batch_size):\n",
    "            spikes = spikes_list[sample]\n",
    "            convolved_spikes = convolved_spikes_list[sample]\n",
    "            \n",
    "            hid_spikes_list = spikes[None, :, n_vis_neurons:]\n",
    "            convolved_hid_spikes_list = convolved_spikes[None, :, n_vis_neurons:]\n",
    "            vis_spikes = spikes[:, :n_vis_neurons]\n",
    "            convolved_vis_spikes = convolved_spikes[:, :n_vis_neurons]\n",
    "            loss -= inf_model.complete_log_likelihood(hid_spikes_list, convolved_hid_spikes_list, vis_spikes, convolved_vis_spikes)[0]\n",
    "        \n",
    "        loss /= batch_size\n",
    "        loss.backward()\n",
    "        inf_optimizer.step()\n",
    "        inf_optimizer.zero_grad()\n",
    "        \n",
    "        epoch_loss_list[epoch] += loss.item()\n",
    "    epoch_loss_list[epoch] /= len(train_dataloader)\n",
    "    \n",
    "    if epoch % print_freq == 0:\n",
    "        with torch.no_grad():\n",
    "            print(epoch, epoch_loss_list[epoch], flush=True)\n",
    "torch.save(inf_model.state_dict(), f'model/GLM.pt')\n",
    "            \n",
    "def evaluate_rgc_0(inf_model, spikes_list, convolved_spikes_list, seed: int = 0):\n",
    "    n_samples = spikes_list.shape[0]\n",
    "    df = pd.DataFrame(index=np.arange(n_samples), columns=['marginal log-likelihood', 'ELBO'])\n",
    "    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for sample in range(n_samples):\n",
    "            spikes = spikes_list[sample]\n",
    "            convolved_spikes = convolved_spikes_list[sample]\n",
    "            \n",
    "            hid_spikes_list = spikes[None, :, n_vis_neurons:]\n",
    "            convolved_hid_spikes_list = convolved_spikes[None, :, n_vis_neurons:]\n",
    "            vis_spikes = spikes[:, :n_vis_neurons]\n",
    "            convolved_vis_spikes = convolved_spikes[:, :n_vis_neurons]\n",
    "            df.at[sample, 'marginal log-likelihood'] = inf_model.complete_log_likelihood(hid_spikes_list, convolved_hid_spikes_list, vis_spikes, convolved_vis_spikes)[0]\n",
    "            df.at[sample, 'ELBO'] = np.nan\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "df = evaluate_rgc_0(inf_model, vis_spikes_list_test, convolved_vis_spikes_list_test).mean().to_frame().T\n",
    "df['time'] = np.nan\n",
    "df.to_csv(f'csv/GLM.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d41000f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cli726]",
   "language": "python",
   "name": "conda-env-.conda-cli726-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
